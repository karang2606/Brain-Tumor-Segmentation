{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cba32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import glob\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imsave\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "import random\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d2a04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This part of the code to get an initial understanding of the dataset.\n",
    "#################################\n",
    "#PART 1: Load sample images and visualize\n",
    "#Includes, dividing each image by its max to scale them to [0,1]\n",
    "#Converting mask from float to uint8\n",
    "#Changing mask pixel values (labels) from 4 to 3 (as the original labels are 0, 1, 2, 4)\n",
    "#Visualize\n",
    "###########################################\n",
    "#View a few images\n",
    "\n",
    "#Note: Segmented file name in Folder 355 has a weird name. Rename it to match others.\n",
    "\n",
    "TRAIN_DATASET_PATH = './BraTS2021_train/'\n",
    "#VALIDATION_DATASET_PATH = 'BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n",
    "\n",
    "test_image_flair=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_00000/BraTS2021_00000_flair.nii.gz').get_fdata()\n",
    "print(test_image_flair.max())\n",
    "#Scalers are applied to 1D so let us reshape and then reshape back to original shape. \n",
    "test_image_flair=scaler.fit_transform(test_image_flair.reshape(-1, test_image_flair.shape[-1])).reshape(test_image_flair.shape)\n",
    "\n",
    "\n",
    "test_image_t1=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_00000/BraTS2021_00000_t1.nii.gz').get_fdata()\n",
    "test_image_t1=scaler.fit_transform(test_image_t1.reshape(-1, test_image_t1.shape[-1])).reshape(test_image_t1.shape)\n",
    "\n",
    "test_image_t1ce=nib.load(TRAIN_DATASET_PATH +'BraTS2021_00000/BraTS2021_00000_t1ce.nii.gz').get_fdata()\n",
    "test_image_t1ce=scaler.fit_transform(test_image_t1ce.reshape(-1, test_image_t1ce.shape[-1])).reshape(test_image_t1ce.shape)\n",
    "\n",
    "test_image_t2=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_00000/BraTS2021_00000_t2.nii.gz').get_fdata()\n",
    "test_image_t2=scaler.fit_transform(test_image_t2.reshape(-1, test_image_t2.shape[-1])).reshape(test_image_t2.shape)\n",
    "\n",
    "test_mask=nib.load(TRAIN_DATASET_PATH + 'BraTS2021_00000/BraTS2021_00000_seg.nii.gz').get_fdata()\n",
    "test_mask=test_mask.astype(np.uint8)\n",
    "\n",
    "print(np.unique(test_mask))  #0, 1, 2, 4 (Need to reencode to 0, 1, 2, 3)\n",
    "test_mask[test_mask==4] = 3  #Reassign mask values 4 to 3\n",
    "print(np.unique(test_mask)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_slice=random.randint(0, test_mask.shape[2])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.imshow(test_image_flair[:,:,n_slice], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(232)\n",
    "plt.imshow(test_image_t1[:,:,n_slice], cmap='gray')\n",
    "plt.title('Image t1')\n",
    "plt.subplot(233)\n",
    "plt.imshow(test_image_t1ce[:,:,n_slice], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(234)\n",
    "plt.imshow(test_image_t2[:,:,n_slice], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(235)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d38ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#PART 2: Explore the process of combining images to channels and divide them to patches\n",
    "#Includes...\n",
    "#Combining all 4 images to 4 channels of a numpy array.\n",
    "#\n",
    "################################################\n",
    "#Flair, T1CE, annd T2 have the most information\n",
    "#Combine t1ce, t2, and flair into single multichannel image\n",
    "\n",
    "combined_x = np.stack([test_image_flair, test_image_t1ce, test_image_t2], axis=3)\n",
    "\n",
    "#Crop to a size to be divisible by 64 so we can later extract 64x64x64 patches. \n",
    "#cropping x, y, and z\n",
    "#combined_x=combined_x[24:216, 24:216, 13:141]\n",
    "\n",
    "combined_x=combined_x[56:184, 56:184, 13:141] #Crop to 128x128x128x4\n",
    "\n",
    "#Do the same for mask\n",
    "test_mask = test_mask[56:184, 56:184, 13:141]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c043ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_slice=random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.imshow(combined_x[:,:,n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(142)\n",
    "plt.imshow(combined_x[:,:,n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(143)\n",
    "plt.imshow(combined_x[:,:,n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(144)\n",
    "plt.imshow(test_mask[:,:,n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "imsave('./combined255.tif', combined_x)\n",
    "np.save('./combined255.npy', combined_x)\n",
    "#Verify image is being read properly\n",
    "#my_img=imread('BraTS2020_TrainingData/combined255.tif')\n",
    "\n",
    "my_img=np.load('./combined255.npy')\n",
    "\n",
    "comparison = combined_x == my_img\n",
    "equal_arrays = comparison.all()\n",
    "  \n",
    "print(equal_arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f0d55e",
   "metadata": {},
   "source": [
    "### Generate tumor core and enhancing tumor and corrosponding inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab3edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#####################################\n",
    "#End of understanding the dataset. Now get it organized.\n",
    "#####################################\n",
    "\n",
    "#Now let us apply the same as above to all the images...\n",
    "#Merge channels, crop, patchify, save\n",
    "#GET DATA READY =  GENERATORS OR OTHERWISE\n",
    "\n",
    "#Keras datagenerator does ntot support 3d\n",
    "\n",
    "# # # images lists harley\n",
    "\n",
    "flair_list = sorted(glob.glob('./BraTS2021_train/*/*flair.nii.gz'))\n",
    "t1ce_list = sorted(glob.glob('./BraTS2021_train/*/*t1ce.nii.gz'))\n",
    "t2_list = sorted(glob.glob('./BraTS2021_train/*/*t2.nii.gz'))\n",
    "t1_list = sorted(glob.glob('./BraTS2021_train/*/*t1.nii.gz'))\n",
    "mask_list = sorted(glob.glob('./BraTS2021_train/*/*seg.nii.gz'))\n",
    "\n",
    "#Each volume generates 18 64x64x64x4 sub-volumes.\n",
    "#Total 369 volumes = 6642 sub volumes\n",
    "image_path='./data/images'\n",
    "mask_path='./data/masks'\n",
    "\n",
    "# Check whether the specified path exists or not\n",
    "if not os.path.exists(image_path):\n",
    "\n",
    "    # Create a new directory because it does not exist \n",
    "    os.makedirs(image_path)\n",
    "\n",
    "if not os.path.exists(mask_path):\n",
    "    os.makedirs(mask_path)\n",
    "\n",
    "print(\"Now preparing image and masks number: \")\n",
    "useless = 0\n",
    "\n",
    "for img in tqdm(range(len(flair_list))):   #Using t1_list as all lists are of same size\n",
    "  \n",
    "    temp_mask=nib.load(mask_list[img]).get_fdata()\n",
    "    temp_mask=temp_mask.astype(np.uint8)\n",
    "    \n",
    "    #print(np.unique(temp_mask))\n",
    "    \n",
    "    temp_mask = temp_mask[56:184, 56:184, 13:141]\n",
    "\n",
    "    val, counts = np.unique(temp_mask, return_counts=True)\n",
    "    if (1 - (counts[0]/counts.sum())) > 0.01:  #At least 1% useful volume with labels that are not 0\n",
    "#         print(\"Save Me\")\n",
    "\n",
    "        temp_image_t1ce=nib.load(t1ce_list[img]).get_fdata()\n",
    "        temp_image_t1ce=scaler.fit_transform(temp_image_t1ce.reshape(-1, temp_image_t1ce.shape[-1])).reshape(temp_image_t1ce.shape)\n",
    "\n",
    "        temp_image_t2=nib.load(t2_list[img]).get_fdata()\n",
    "        temp_image_t2=scaler.fit_transform(temp_image_t2.reshape(-1, temp_image_t2.shape[-1])).reshape(temp_image_t2.shape)\n",
    "        \n",
    "        temp_image_t1=nib.load(t1_list[img]).get_fdata()\n",
    "        temp_image_t1=scaler.fit_transform(temp_image_t1.reshape(-1, temp_image_t1.shape[-1])).reshape(temp_image_t1.shape)\n",
    "        \n",
    "        temp_image_flair=nib.load(flair_list[img]).get_fdata()\n",
    "        temp_image_flair=scaler.fit_transform(temp_image_flair.reshape(-1, temp_image_flair.shape[-1])).reshape(temp_image_flair.shape)\n",
    "\n",
    "        temp_combined_images = np.stack([temp_image_flair, temp_image_t2, temp_image_t1ce, temp_image_t1], axis=3)\n",
    "        temp_combined_images=temp_combined_images[56:184, 56:184, 13:141]\n",
    "        \n",
    "        #Crop to a size to be divisible by 64 so we can later extract 64x64x64 patches. \n",
    "        #cropping x, y, and z\n",
    "        whole_tumor = temp_mask.copy() \n",
    "        whole_tumor[whole_tumor==2] = 1  #Reassign mask values 4 to 3\n",
    "        whole_tumor[whole_tumor==4] = 1  #Reassign mask values 4 to 3\n",
    "\n",
    "        mask_1 = np.expand_dims(whole_tumor, axis=-1)\n",
    "        merged = temp_combined_images*mask_1\n",
    "\n",
    "        tumor_core = temp_mask.copy()\n",
    "        tumor_core[tumor_core==2] = 0  #Reassign mask values 4 to 3\n",
    "        tumor_core[tumor_core==4] = 1  #Reassign mask values 4 to 3\n",
    "        \n",
    "        enhancing_tumor = temp_mask.copy()\n",
    "        enhancing_tumor[enhancing_tumor==1] = 0  #Reassign mask values 4 to 3\n",
    "        enhancing_tumor[enhancing_tumor==2] = 0  #Reassign mask values 4 to 3\n",
    "        enhancing_tumor[enhancing_tumor==4] = 1  #Reassign mask values 4 to 3\n",
    "        \n",
    "        temp_combined_masks = np.stack([whole_tumor, tumor_core, enhancing_tumor], axis=3)\n",
    "        \n",
    "        np.save(image_path + '/image_'+str(img)+'.npy', temp_combined_images)\n",
    "        np.save(mask_path + '/mask_'+str(img)+'.npy', temp_combined_masks)\n",
    "        \n",
    "    else:\n",
    "        useless+=1\n",
    "print(\"Finished\")\n",
    "print(\"Usefull Images:\",len(t2_list)-useless)\n",
    "print(\"Useless Images:\",useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2b5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training data into train and validation\n",
    "\n",
    "\"\"\"\n",
    "Code for splitting folder into train, test, and val.\n",
    "Once the new folders are created rename them and arrange in the format below to be used\n",
    "for semantic segmentation using data generators. \n",
    "pip install split-folders\n",
    "\"\"\"\n",
    "\n",
    "input_folder = './data/'\n",
    "output_folder = './data2/'\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Split with a ratio.\n",
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.8, .2), group_prefix=None) # default values\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4603c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose random Image from folder \n",
    "image = np.load('./data2/val/images' + '/image_228.npy')\n",
    "mask = np.load('./data2/val/masks' + '/mask_228.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_slice=random.randint(0, temp_mask.shape[2])\n",
    "n_slice = 55\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(151)\n",
    "plt.imshow(image[:,:,n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(152)\n",
    "plt.imshow(mask[:,:,n_slice,0])\n",
    "plt.title('whole_tumor')\n",
    "plt.subplot(153)\n",
    "plt.imshow(mask[:,:,n_slice, 1])\n",
    "plt.title('tumor_core')\n",
    "plt.subplot(154)\n",
    "plt.imshow(mask[:,:,n_slice,2])\n",
    "plt.title('enhancing_tumor')\n",
    "plt.subplot(155)\n",
    "plt.imshow(np.sum(mask, axis = 3)[:,:,n_slice ])\n",
    "plt.title('All')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
